{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1FxUNjREFyo"
   },
   "source": [
    "# **页面基本设置**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1592956076835,
     "user": {
      "displayName": "Chuanchao Xu",
      "photoUrl": "",
      "userId": "08016207472332924278"
     },
     "user_tz": -480
    },
    "id": "oCCsWp-NJ6KF",
    "outputId": "d804ea3f-0cd0-404f-819b-4a8f10e294cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/UTC&MTC/RUL-Net-master/XCC_File\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/UTC&MTC/RUL-Net-master/XCC_File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1172,
     "status": "ok",
     "timestamp": 1592500801424,
     "user": {
      "displayName": "Chuanchao Xu",
      "photoUrl": "",
      "userId": "08016207472332924278"
     },
     "user_tz": -480
    },
    "id": "uiSt6DtJJ_17",
    "outputId": "a7b245a4-1dcc-473b-8535-b5056690fe63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2E_hQvcSqri"
   },
   "source": [
    "# **加载文件并归一化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N3QMdT2FSpNd"
   },
   "outputs": [],
   "source": [
    "#数据加载\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"https://raw.githubusercontent.com/sivaji1233/09_turbofan_rul/master/data/train_FD001.txt\", sep = ' ', header = None)\n",
    "\n",
    "col_list = ['unit', 'time', 'os_1', 'os_2', 'os_3', 'sm_1', 'sm_2', 'sm_3', 'sm_4', 'sm_5', 'sm_6', 'sm_7', 'sm_8', 'sm_9', 'sm_10', 'sm_11', 'sm_12', 'sm_13', 'sm_14', 'sm_15', 'sm_16', 'sm_17', 'sm_18', 'sm_19', 'sm_20', 'sm_21']\n",
    "\n",
    "df_train = df_train[list(range(26))]\n",
    "df_train.columns = col_list\n",
    "print(df_train.shape[0])\n",
    "print(df_train.head())\n",
    "\n",
    "# 数据可视化\n",
    "\n",
    "\n",
    "# 去除无关变量\n",
    "new_col_list = ['unit', 'time', 'os_1', 'os_2', 'sm_2', 'sm_3', 'sm_4', 'sm_6', 'sm_7', 'sm_8', 'sm_9', 'sm_11', 'sm_12', 'sm_13', 'sm_14', 'sm_15', 'sm_17', 'sm_20', 'sm_21']\n",
    "df_train = df_train[new_col_list]\n",
    "#df_test = df_test[new_col_list]\n",
    "\n",
    "\n",
    "#归一化\n",
    "def regularit(df):\n",
    "    newDataFrame = pd.DataFrame(index=df.index)\n",
    "    columns = df.columns.tolist()\n",
    "    columns_0_4 = columns[:4]\n",
    "    print(columns_0_4)\n",
    "    for c in columns:\n",
    "      if c in columns_0_4:\n",
    "        print('yes')\n",
    "        newDataFrame[c] = df[c]\n",
    "        continue\n",
    "      d = df[c]\n",
    "      MAX = d.max()\n",
    "      MIN = d.min()\n",
    "      newDataFrame[c] = ((d - MIN) / (MAX - MIN)).tolist()\n",
    "    return newDataFrame\n",
    "df_train_0_1 = regularit(df_train)\n",
    "print(df_train_0_1.shape[1],df_train_0_1.columns)\n",
    "print(df_train_0_1.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjc8KiOxLll6"
   },
   "source": [
    "# **结合样本均衡性要求和分类问题的类别整理汇总成新样本**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_0FCcRzIS2PW"
   },
   "source": [
    "## *新样本组合（二分类）*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "av_OTYKtSyXy"
   },
   "outputs": [],
   "source": [
    "####提取发生故障时的参数并单开一列做标记\n",
    "number_fault = []\n",
    "number_no_fault = []\n",
    "\n",
    "df_train_xcc = df_train_0_1.copy()\n",
    "df_train_xcc['fault?'] = 0  #新增列'fault?',发生故障标记为1，未发生故障标记为0\n",
    "print(df_train_xcc.head())\n",
    " \n",
    "for i in range(1,df_train_xcc.shape[0]):\n",
    "  if df_train_xcc.loc[i,'time']<df_train_xcc.loc[i-1,'time']:\n",
    "    number_fault.append(i-1)\n",
    "    df_train_xcc.loc[i-1,'fault?'] = 1 \n",
    "  else:\n",
    "    number_no_fault.append(i)\n",
    "number_fault.append(df_train_xcc.shape[0]-1)  #补最后一个发动机的故障数据\n",
    "df_train_xcc.loc[df_train_xcc.shape[0]-1,'fault?'] = 1\n",
    "df_fault = df_train_xcc.loc[number_fault,:]\n",
    "print(len(number_fault))\n",
    "df_no_fault = df_train_xcc.loc[number_no_fault,:]\n",
    "print(len(number_no_fault))\n",
    " \n",
    "df_train_xcc.head(195)\n",
    " \n",
    "#导出故障时刻的汇总数据\n",
    "#df_fault.to_csv('fault_state.csv')\n",
    " \n",
    " \n",
    "###进行新样本组合：\n",
    "'''  \n",
    "通常将样本类别比例超过4：1或者3：1的数据看作是不均衡数据,\n",
    "设置样本的均衡比例包括3：1、2：1、1：1、1：2，分别对应的样本量为400、300、200、150\n",
    "设置样本的不均衡比例包括：4：1、10：1、20：1，分别对应的样本量为500、1100、2100\n",
    "'''\n",
    "import random\n",
    "sample_type = {'eq':[400,300,200,150],'uneq':[500,1100,2100]}\n",
    "sample_type['eq']\n",
    "#随机生成均衡/不均衡样本\n",
    "for j in sample_type.keys():\n",
    "  for i in sample_type[j]:\n",
    "    number_fault_temp = number_fault.copy()\n",
    "    number_no_fault_300 = random.sample(number_no_fault, i-100)\n",
    "    number_fault_temp.extend(number_no_fault_300)\n",
    "    number_fault_temp.sort()   #得到序号并排列\n",
    "    df_sample_temp = df_train_xcc.loc[number_fault_temp,:]  #得到对应行数的样本\n",
    " \n",
    "    df_sample_temp.drop(columns=['unit','time'],inplace=True)\n",
    "    print(df_sample_temp.head())\n",
    "    df_sample_temp.to_csv('/content/drive/My Drive/UTC&MTC/RUL-Net-master/XCC_File/2_class/'+j+'/sample_'+str(i)+'.csv')\n",
    "    print(len(number_fault_temp),'\\n',number_fault_temp,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2P4j7EsT9P8l"
   },
   "source": [
    "二分类算法执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BX1nsMzhCB2"
   },
   "outputs": [],
   "source": [
    "!python D_R_E_S_2_class.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PULhcYc-zo7"
   },
   "source": [
    "## *新样本组合（多分类）*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIKKuz8T-y7I"
   },
   "outputs": [],
   "source": [
    "###进行新样本组合\n",
    "'''\n",
    "多分类的类别个数拟定，按照crnn的计算结果，拟定间隔为20，按照发生故障的时间递增地将类别标签设置为1，2，3，...。\n",
    "标记0为无故障状态，故障样本的故障时间与标签严格对应，标签不一定序次连续。\n",
    "设置样本的均衡比例分为几种：\n",
    "①各类别标签的样本量相等（包括0）\n",
    "②按照二分类的比例，将故障样本看成整体，故障样本内部类别比例不做改变。\n",
    "'''\n",
    " \n",
    "#查看故障样本的故障发生时间并做标记\n",
    "fault_point = df_train_xcc.loc[number_fault,'time'].to_list()\n",
    "print(min(fault_point),max(fault_point))\n",
    "center_of_gap = [j for j in range(min(fault_point)+10,max(fault_point)-10,20)]\n",
    "#class_fault = range(1,len(center_of_gap)+1)\n",
    "#print(center_of_gap,'\\n',class_fault)\n",
    "fault_class = []\n",
    "for i in fault_point:\n",
    "  abs_error = [abs(j-i) for j in center_of_gap]\n",
    "  index_fault = abs_error.index(min(abs_error)) + 1\n",
    "  fault_class.append(index_fault)\n",
    "print(fault_class)  \n",
    " \n",
    "# 故障样本中类别统计\n",
    "class_times = []\n",
    "for i in range(1,12):\n",
    "  counter = 0\n",
    "  for j in fault_class:\n",
    "    if j==i:\n",
    "      counter = counter + 1\n",
    "  class_times.append(counter)\n",
    "  #print('class '+ str(i) + '元素个数为：' + counter )\n",
    "  print(counter)\n",
    "print(class_times)\n",
    " \n",
    "'''\n",
    "# 故障样本中类别统计条形图\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('CLASS')\n",
    "plt.ylabel('Number of Times')\n",
    "plt.hist(class_times)\n",
    "plt.show()\n",
    " \n",
    "'''\n",
    "#对故障&非故障数据重新标记  基于二分类已经标记过的数据\n",
    " \n",
    "df_train_xcc_mc = df_train_xcc.copy()   # mc表示multi classification\n",
    "number_fault_mc = number_fault.copy()\n",
    "print(df_train_xcc_mc,'\\n',number_fault_mc)\n",
    "j = 0\n",
    "for i in number_fault_mc:\n",
    "  df_train_xcc_mc.loc[i,'fault?'] = fault_class[j]\n",
    "  j = j+1\n",
    "print(df_train_xcc_mc.head(2890))\n",
    " \n",
    "#生成均衡样本（令无故障样本量 与 故障样本/故障类别=100/11=9 取值为9）\n",
    "import random\n",
    "number_no_fault_9 = random.sample(number_no_fault, 9)\n",
    "number_fault_temp = number_fault.copy()\n",
    "number_fault_temp.extend(number_no_fault_9)\n",
    "number_fault_temp.sort()   #得到序号并排列\n",
    "df_sample_temp = df_train_xcc_mc.loc[number_fault_temp,:]  #得到对应行数的样本\n",
    "df_sample_temp.drop(columns=['unit','time'],inplace=True)  #删除'unit'和'time'列\n",
    "print(df_sample_temp.head())\n",
    "df_sample_temp.to_csv('/content/drive/My Drive/UTC&MTC/RUL-Net-master/XCC_File/multi_class/sample_eq.csv')\n",
    "#print(len(number_fault_temp),'\\n',number_fault_temp,'\\n\\n')\n",
    " \n",
    "#生成非均衡样本（令无故障样本 与 故障样本呈二分类的比例\n",
    "'''\n",
    "设置样本的均衡比例包括3：1、2：1、1：1、1：2，分别对应的样本量为127、118、109、105\n",
    "设置样本的不均衡比例包括：4：1、10：1、20：1，分别对应的样本量为136、190、280\n",
    "'''\n",
    "import random\n",
    "sample_type = {'eq':[127,118,109,105],'uneq':[136,190,280]}\n",
    "sample_type['eq']\n",
    "#随机生成均衡/不均衡样本\n",
    "for j in sample_type.keys():\n",
    "  for i in sample_type[j]:\n",
    "    number_fault_temp = number_fault.copy()\n",
    "    number_no_fault_300 = random.sample(number_no_fault, i-100)\n",
    "    number_fault_temp.extend(number_no_fault_300)\n",
    "    number_fault_temp.sort()   #得到序号并排列\n",
    "    df_sample_temp = df_train_xcc_mc.loc[number_fault_temp,:]  #得到对应行数的样本\n",
    " \n",
    "    df_sample_temp.drop(columns=['unit','time'],inplace=True)\n",
    "    print(df_sample_temp.head())\n",
    "    df_sample_temp.to_csv('/content/drive/My Drive/UTC&MTC/RUL-Net-master/XCC_File/multi_class/'+j+'/sample_'+str(i)+'.csv')\n",
    "    print(len(number_fault_temp),'\\n',number_fault_temp,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7k6cxAaV9jjO"
   },
   "source": [
    "多分类算法执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZ1LNjmT9oQI"
   },
   "outputs": [],
   "source": [
    "!python D_R_E_S_multi_class.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxLAVFrdv2Pu"
   },
   "source": [
    "# **按照C-MAPSS的训练和测试划分进行算法验证**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fuDVhFjowD7m"
   },
   "source": [
    "## 数据加载及分类样本生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLs_xdHOEeOe"
   },
   "source": [
    "#### 数据加载、数据可视化、去除无关变量、归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eii21dIZEqEc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"https://raw.githubusercontent.com/sivaji1233/09_turbofan_rul/master/data/train_FD003.txt\", sep = ' ', header = None)\n",
    "df_test = pd.read_csv(\"https://raw.githubusercontent.com/sivaji1233/09_turbofan_rul/master/data/test_FD003.txt\", sep = ' ', header = None)\n",
    "\n",
    "col_list = ['unit', 'time', 'os_1', 'os_2', 'os_3', 'sm_1', 'sm_2', 'sm_3', 'sm_4', 'sm_5', 'sm_6', 'sm_7', 'sm_8', 'sm_9', 'sm_10', 'sm_11', 'sm_12', 'sm_13', 'sm_14', 'sm_15', 'sm_16', 'sm_17', 'sm_18', 'sm_19', 'sm_20', 'sm_21']\n",
    "\n",
    "df_train = df_train[list(range(26))]\n",
    "df_train.columns = col_list\n",
    "\n",
    "df_test = df_test[list(range(26))]\n",
    "df_test.columns = col_list\n",
    "#print(df_test.shape[0])\n",
    "df_test.head()\n",
    "\n",
    "# 数据可视化\n",
    "\n",
    "\n",
    "# 去除无关变量\n",
    "new_col_list = ['unit', 'time', 'os_1', 'os_2', 'sm_2', 'sm_3', 'sm_4', 'sm_6', 'sm_7', 'sm_8', 'sm_9', 'sm_11', 'sm_12', 'sm_13', 'sm_14', 'sm_15', 'sm_17', 'sm_20', 'sm_21']\n",
    "df_train = df_train[new_col_list]\n",
    "df_test = df_test[new_col_list]\n",
    "\n",
    "\n",
    "# 归一化\n",
    "def regularit(df):\n",
    "    newDataFrame = pd.DataFrame(index=df.index)\n",
    "    columns = df.columns.tolist()\n",
    "    columns_0_4 = columns[:4]\n",
    "    print(columns_0_4)\n",
    "    for c in columns:\n",
    "      if c in columns_0_4:\n",
    "        print('yes')\n",
    "        newDataFrame[c] = df[c]\n",
    "        continue\n",
    "      d = df[c]\n",
    "      MAX = d.max()\n",
    "      MIN = d.min()\n",
    "      newDataFrame[c] = ((d - MIN) / (MAX - MIN)).tolist()\n",
    "    return newDataFrame\n",
    "df_train_normalized = regularit(df_train)\n",
    "print(df_train_normalized.shape[0],df_train_normalized.columns)\n",
    "#print(df_train_normalized.head())\n",
    "\n",
    "df_test_normalized = regularit(df_test)\n",
    "print(df_test_normalized.shape[0],df_test_normalized.columns)\n",
    "#print(df_test_normalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgPY8-TKEwjS"
   },
   "source": [
    "#### 0-1标记（二分类样本生成）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsGuAsX0v-mx"
   },
   "outputs": [],
   "source": [
    "# 0-1标记\n",
    "def mark_0_1(df):\n",
    "  df_xcc = df.copy()\n",
    "  number_fault = []\n",
    "  number_no_fault = []\n",
    "  df_xcc['fault?'] = 0  #新增列'fault?',发生故障标记为1，未发生故障标记为0\n",
    "  #print(df_train_xcc.head())\n",
    "  for i in range(1,df_xcc.shape[0]):\n",
    "    if df_xcc.loc[i,'time']<df_xcc.loc[i-1,'time']:\n",
    "      number_fault.append(i-1)\n",
    "      df_xcc.loc[i-1,'fault?'] = 1 \n",
    "    else:\n",
    "      number_no_fault.append(i)\n",
    "  number_fault.append(df_xcc.shape[0]-1)  #补最后一个发动机的故障数据\n",
    "  df_xcc.loc[df_xcc.shape[0]-1,'fault?'] = 1\n",
    "  df_fault = df_xcc.loc[number_fault,:]\n",
    "  #print(len(number_fault))\n",
    "  df_no_fault = df_xcc.loc[number_no_fault,:]\n",
    "  #print(len(number_no_fault))\n",
    "  number_sample = number_fault + number_no_fault\n",
    "  number_sample.sort()\n",
    "  \n",
    "  #df_marked.head(195)\n",
    "  return df_xcc, number_fault   #此处的df_trian_xcc是带了0-1标签的。\n",
    "\n",
    "df_train_0_1_marked,number_fault_train = mark_0_1(df_train_normalized)\n",
    "df_train_0_1_marked.to_csv('/content/drive/My Drive/UTC&MTC/RUL-Net-master/XCC_File/2_class_for_all_data/df_train_0_1_marked.csv')\n",
    "#print(df_train_0_1_marked.shape)\n",
    "#print(number_fault)\n",
    "#print(df_train_0_1_marked.loc[number_fault_train,'fault?'])\n",
    "\n",
    "df_test_0_1_marked,number_fault_test = mark_0_1(df_test_normalized)\n",
    "df_test_0_1_marked.to_csv('/content/drive/My Drive/UTC&MTC/RUL-Net-master/XCC_File/2_class_for_all_data/df_test_0_1_marked.csv')\n",
    "#print(df_test_0_1_marked.shape)\n",
    "#print(df_test_0_1_marked.loc[number_fault_test,'fault?'])\n",
    "\n",
    "\n",
    "print(number_fault_train)\n",
    "\n",
    "'''\n",
    "  # 生成均衡样本\n",
    "  import random\n",
    "  number_no_fault_9 = random.sample(number_no_fault, 9)\n",
    "  number_fault_temp = number_fault.copy()\n",
    "  number_fault_temp.extend(number_no_fault_9)\n",
    "  number_fault_temp.sort()   #得到序号并排列\n",
    "  df_sample_temp = df_train_xcc_mc.loc[number_fault_temp,:]  #得到对应行数的样本\n",
    "  df_sample_temp.drop(columns=['unit','time'],inplace=True)  #删除'unit'和'time'列\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UnunjtlE5xB"
   },
   "source": [
    "#### 1-11标记（多分类样本生成）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "B0o0sHyvE-Zc"
   },
   "outputs": [],
   "source": [
    "#@title 默认标题文本\n",
    "# 1-11标记\n",
    "def mark_1_11(df_normalized):\n",
    "  df_xcc, number_fault = mark_0_1(df_normalized)    # 继承用于二分类的已标记的样本\n",
    "  df_xcc_mc = df_xcc.copy()\n",
    "  #查看故障样本的故障发生时间并做标记\n",
    "  fault_point = df_xcc.loc[number_fault,'time'].to_list()\n",
    "  print(min(fault_point),max(fault_point))\n",
    "  center_of_gap = [j for j in range(min(fault_point)+10,max(fault_point)-10,20)]\n",
    "  #class_fault = range(1,len(center_of_gap)+1)\n",
    "  #print(center_of_gap,'\\n',class_fault)\n",
    "  fault_class = []\n",
    "  for i in fault_point:\n",
    "    abs_error = [abs(j-i) for j in center_of_gap]\n",
    "    index_fault = abs_error.index(min(abs_error)) + 1\n",
    "    fault_class.append(index_fault)\n",
    "  print(fault_class)  \n",
    "\n",
    "\n",
    "  # 构建带标记的'fault?'列\n",
    "  fault_col_mc = [0]*df_xcc.shape[0]\n",
    "  for i in range(df_xcc.shape[0]):\n",
    "    for j in number_fault:\n",
    "      if i == j :\n",
    "        fault_col_mc[i] = fault_class[number_fault.index(j)]\n",
    "  print(fault_col_mc[1005])\n",
    "\n",
    "  ## 方法一：删除'faul?'列，新增'fault_mc'列\n",
    "  df_xcc_mc.drop(columns='fault?',inplace=True)\n",
    "  df_xcc_mc['fault_mc'] = fault_col_mc\n",
    "  print(df_xcc_mc.loc[number_fault[3],'fault_mc'])\n",
    "\n",
    "  \n",
    "  return df_xcc_mc\n",
    "\n",
    "df_train_1_11_marked = mark_1_11(df_train_normalized)\n",
    "df_train_1_11_marked.to_csv('/content/drive/My Drive/UTC&MTC/RUL-Net-master/XCC_File/multi_class_for_all_data/df_train_1_11_marked.csv')\n",
    "#print(df_train_0_1_marked.shape)\n",
    "#print(number_fault)\n",
    "#print(df_train_0_1_marked.loc[number_fault_train,'fault?'])\n",
    "\n",
    "df_test_1_11_marked = mark_1_11(df_test_normalized)\n",
    "df_test_1_11_marked.to_csv('/content/drive/My Drive/UTC&MTC/RUL-Net-master/XCC_File/multi_class_for_all_data/df_test_1_11_marked.csv')\n",
    "#print(df_test_0_1_marked.shape)\n",
    "#print(df_test_0_1_marked.loc[number_fault_test,'fault?'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t3oZ4-pcHxId"
   },
   "source": [
    "## 应用D_R_E_S方法(二分类&多分类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58747,
     "status": "ok",
     "timestamp": 1592956198135,
     "user": {
      "displayName": "Chuanchao Xu",
      "photoUrl": "",
      "userId": "08016207472332924278"
     },
     "user_tz": -480
    },
    "id": "RpABKT6mHwbH",
    "outputId": "9eb14f3c-261b-4530-8ce6-e791009b609a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  1.00000000e+00 -5.00000000e-04 ...  2.72727273e-01\n",
      "   5.59523810e-01  4.46330828e-01]\n",
      " [ 1.00000000e+00  2.00000000e+00  8.00000000e-04 ...  3.63636364e-01\n",
      "   4.88095238e-01  5.34836256e-01]\n",
      " [ 1.00000000e+00  3.00000000e+00 -1.40000000e-03 ...  2.72727273e-01\n",
      "   4.04761905e-01  4.58576862e-01]\n",
      " ...\n",
      " [ 1.00000000e+02  1.50000000e+02 -1.60000000e-03 ...  7.27272727e-01\n",
      "   1.30952381e-01  1.81463958e-01]\n",
      " [ 1.00000000e+02  1.51000000e+02 -2.30000000e-03 ...  6.36363636e-01\n",
      "   8.33333333e-02  1.88050840e-01]\n",
      " [ 1.00000000e+02  1.52000000e+02  0.00000000e+00 ...  7.27272727e-01\n",
      "   2.32142857e-01  1.96771500e-01]] \n",
      " [0 0 0 ... 0 0 1] \n",
      " [[ 1.00000000e+00  1.00000000e+00 -5.00000000e-04 ...  2.72727273e-01\n",
      "   5.59523810e-01  4.46330828e-01]\n",
      " [ 1.00000000e+00  2.00000000e+00  8.00000000e-04 ...  3.63636364e-01\n",
      "   4.88095238e-01  5.34836256e-01]\n",
      " [ 1.00000000e+00  3.00000000e+00 -1.40000000e-03 ...  2.72727273e-01\n",
      "   4.04761905e-01  4.58576862e-01]\n",
      " ...\n",
      " [ 1.00000000e+02  1.50000000e+02 -1.60000000e-03 ...  7.27272727e-01\n",
      "   1.30952381e-01  1.81463958e-01]\n",
      " [ 1.00000000e+02  1.51000000e+02 -2.30000000e-03 ...  6.36363636e-01\n",
      "   8.33333333e-02  1.88050840e-01]\n",
      " [ 1.00000000e+02  1.52000000e+02  0.00000000e+00 ...  7.27272727e-01\n",
      "   2.32142857e-01  1.96771500e-01]] \n",
      " [0 0 0 ... 0 0 1]\n",
      "决策树Acc: 100.00%\n",
      "随机森林Acc: 100.00%\n",
      "极端随机树Acc: 100.00%\n",
      "支持向量机Acc: 99.60%\n",
      "1.0 \n",
      " 1.0 \n",
      " 1.0 \n",
      " 0.996\n"
     ]
    }
   ],
   "source": [
    "# 二分类\n",
    "from D_R_E_S_2_class_for_all_data import data_load_xcc_original_train_test\n",
    "from D_R_E_S_2_class_for_all_data import methods_classifier\n",
    "\n",
    "X,y,X_,y_ = data_load_xcc_original_train_test(df_train_0_1_marked,df_test_0_1_marked)\n",
    "print(X,'\\n',y,'\\n',X_,'\\n',y_)\n",
    "\n",
    "acc_1,acc_2,acc_3,acc_4 = methods_classifier(X,y,X_,y_)\n",
    "print(acc_1,'\\n',acc_2,'\\n',acc_3,'\\n',acc_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59597,
     "status": "ok",
     "timestamp": 1592956309187,
     "user": {
      "displayName": "Chuanchao Xu",
      "photoUrl": "",
      "userId": "08016207472332924278"
     },
     "user_tz": -480
    },
    "id": "9vUYINZeUQQA",
    "outputId": "4b30da7b-1788-416c-f7f9-e3f93048f40d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  1.00000000e+00 -5.00000000e-04 ...  2.72727273e-01\n",
      "   5.59523810e-01  4.46330828e-01]\n",
      " [ 1.00000000e+00  2.00000000e+00  8.00000000e-04 ...  3.63636364e-01\n",
      "   4.88095238e-01  5.34836256e-01]\n",
      " [ 1.00000000e+00  3.00000000e+00 -1.40000000e-03 ...  2.72727273e-01\n",
      "   4.04761905e-01  4.58576862e-01]\n",
      " ...\n",
      " [ 1.00000000e+02  1.50000000e+02 -1.60000000e-03 ...  7.27272727e-01\n",
      "   1.30952381e-01  1.81463958e-01]\n",
      " [ 1.00000000e+02  1.51000000e+02 -2.30000000e-03 ...  6.36363636e-01\n",
      "   8.33333333e-02  1.88050840e-01]\n",
      " [ 1.00000000e+02  1.52000000e+02  0.00000000e+00 ...  7.27272727e-01\n",
      "   2.32142857e-01  1.96771500e-01]] \n",
      " [0 0 0 ... 0 0 1] \n",
      " [[ 1.00000000e+00  1.00000000e+00 -5.00000000e-04 ...  2.72727273e-01\n",
      "   5.59523810e-01  4.46330828e-01]\n",
      " [ 1.00000000e+00  2.00000000e+00  8.00000000e-04 ...  3.63636364e-01\n",
      "   4.88095238e-01  5.34836256e-01]\n",
      " [ 1.00000000e+00  3.00000000e+00 -1.40000000e-03 ...  2.72727273e-01\n",
      "   4.04761905e-01  4.58576862e-01]\n",
      " ...\n",
      " [ 1.00000000e+02  1.50000000e+02 -1.60000000e-03 ...  7.27272727e-01\n",
      "   1.30952381e-01  1.81463958e-01]\n",
      " [ 1.00000000e+02  1.51000000e+02 -2.30000000e-03 ...  6.36363636e-01\n",
      "   8.33333333e-02  1.88050840e-01]\n",
      " [ 1.00000000e+02  1.52000000e+02  0.00000000e+00 ...  7.27272727e-01\n",
      "   2.32142857e-01  1.96771500e-01]] \n",
      " [0 0 0 ... 0 0 1]\n",
      "决策树Acc: 100.00%\n",
      "随机森林Acc: 100.00%\n",
      "极端随机树Acc: 100.00%\n",
      "支持向量机Acc: 99.60%\n",
      "1.0 \n",
      " 1.0 \n",
      " 1.0 \n",
      " 0.996\n"
     ]
    }
   ],
   "source": [
    "# 多分类\n",
    "from D_R_E_S_multi_class_for_all_data import data_load_xcc_original_train_test\n",
    "from D_R_E_S_multi_class_for_all_data import methods_classifier\n",
    "\n",
    "X,y,X_,y_ = data_load_xcc_original_train_test(df_train_1_11_marked,df_test_1_11_marked)\n",
    "print(X,'\\n',y,'\\n',X_,'\\n',y_)\n",
    "\n",
    "acc_1,acc_2,acc_3,acc_4 = methods_classifier(X,y,X_,y_)\n",
    "print(acc_1,'\\n',acc_2,'\\n',acc_3,'\\n',acc_4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOKMNYnLlc+w5b3opjlU1lX",
   "mount_file_id": "1IxJXiPUg2hqC4jJ6mrVIWSWjHrdn9ITD",
   "name": "C-MAPSS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
